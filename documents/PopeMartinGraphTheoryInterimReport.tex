\documentclass{article}

\begin{document}

\title{Evolving Random Graph Generating Algorithms}

\author{
Pope, Aaron\\
\texttt{aaron.pope@mst.edu}
\and
Martin, Matthew\\
\texttt{mam446@mst.edu}
}

\maketitle

\section{Introduction}

The goal of this research is to use Genetic Programming (GP) techniques to evolve algorithms which generate random graphs that satisfy various conditions. Evolutionary Computing (EC) uses a biologically inspired process to solve a problem by generating a population of potential solutions and selecting the best among them to participate in procreation to create more solutions. This process continues through multiple generations until certain termination criteria are met. GP is a field of EC in which the solutions sought are programs themselves. The candidate programs can be represented as parse trees in which the internal nodes represent operations on the input received from the children nodes and the leaf nodes are chosen from the problem's input.

Traditional GP has several stochastic components. The population is initialized with randomly created solutions, offspring inherit a random selection of attributes from each parent and each offspring has a chance of undergoing a random mutation. Because of these stochastic elements, a GP algorithm will explore possible solutions that might seem counterintuitive to a human developer. While these non-obvious choices are usually inferior, they can, on occasion, lead to a breakthrough in computational efficiency or solution accuracy.

The main challenge in evolving graph algorithms will be creating a set of operations which can be combined to create a candidate solution. The operation set needs to contain a variety of methods in order for the GP to create solutions to different types of problems. However, if the set grows too large, the search space of potential solutions explodes, making a search infeasible. Therefore, the goal is to find a minimal set of operations which are crucial to solving a specific problem or family of problems.

Another challenge is measuring the quality of a candidate solution when determining which solutions will survive and procreate. *Talk about goodness-of-fit to random graph models and possibly METIS stuff*

\section{Related Work}
blah

\section{Approach}

\subsection{Old Stuff}

In our genetic program the representation of the graph that we chose is a $n \times n$ matrix. Each node in the parse tree will take one or more $n \times n$ matrices and return a single $n \times n$ matrix. By making this restriction to $n \times n$ matrices we don't have to worry about the typing problem in standard GPs.
When evolving the graph algorithm there are two main kinds of nodes in the parse tree, terminal nodes, and interior nodes. The terminal nodes are the leaves of the tree and in general are the input to the algorithm. We currently have three different terminal nodes, the adjacency matrix representation of the graph, the degree matrix of the graph, and the identity matrix. More terminal nodes may be added in the future if it is deemed necessary. The interior nodes are broken up into two different categories, matrix operations and graph operations. Matrix operations include operations such as adding or multiplying matrices. Graph operations are operations such as finding the minimal spanning tree or the complement of a graph. Using a combination of matrix and graph operations will give the GP a large search space to solve problems in counterintuitive ways.

The nodes described above will be structured into a parse tree and evaluated in post-order fashion. This means that the GP will start at the terminal nodes and evaluate up the tree until the root node returns a matrix. This matrix is then put through a reducer operation that takes a matrix and returns a value. Some examples of these reduction operations are taking the determinant of the matrix or finding the number of components of the graph.

The best parse tree algorithms we find through evolution will be translated into executable programs. We will compare the performance of our results to current approximation algorithms (if any exist) in terms of accuracy and efficiency. Though our long-term goal is to find algorithms that outperform the current alternatives, the present short-term goal is to provide a proof of concept for evolving graph algorithms using GP techniques.

\subsection{New stuff}

This paper discusses a method using GP to evolve an algorithm that generates a random graph of with a specified nature.  The method proposed uses Koza style GP to evolve a post-ordered parse tree structure that will represent the algorithm. Most random-graph generating algorithms repeat a node adding phase n times to create a random graph of size n. Our algorithm takes advantage of this repetitive nature of random-graph algorithms in such a way that it only evolves the method for adding a node and its connections. In this phase, the parse tree decides which other nodes that the new node is connected to. 
There are two proposed methods that this decision process can be done. One method is for each new node, the algorithm would iterate over every existing node and the parse tree would determine if a connection would be made between that node and the new node. The second method would be for the parse tree to be evaluated one time and determine the set of nodes that the new node would be connected to.  It was determined that the second method would be the preferred option, as it would be easier to construct some of the pre-existing random graph algorithms such as the Erdos-Renyi model. 
The parse tree will be constructed from a set of operations that will be used as the non-terminal nodes and sets of nodes which will be used as the terminal nodes.  Each of the operations will take in one or more sets of nodes and return a single set of nodes. The set of nodes returned by the root node will be the set of nodes that the newly created node will connect to. The terminal nodes will be sets of node such as a random subset of the current node set, the entire node set or the empty set. 
The main nodes that will be used as the non-terminal nodes will be selection nodes. These nodes will take a set of nodes and select a subset of those nodes to return to its parent node. One example is the selection criterion that is used in the Erdos-Renyi model. Every node has a p percent chance of getting selected.  Other selection operations such as k-tournament, proportional selection and others can also be used if there is some measure of the nodes that they can be selected on. This could be the degree of the node or some other property that can be attributed to that node.  Other nodes that will be included are set operation nodes such as union, intersection, and disjoint.  By including selection operations that are taken from current random graph models we are guaranteed to be able to represent those models in the parse tree structure.
To evaluate these parse trees random graphs will be generated using the method described in the parse tree. The parse trees will be given a fitness value based on how closely the graphs they generate comply with a user defined model. For the experiments that will be constructed, the models will be fairly rudimentary to show a proof of concept. An example of this could be all nodes have an equal or near equal degree and the degree is roughly n/3, n being the number of nodes in the graph.  The user can specify the model and the standard deviation away from the model that the random graphs may have. For the fitness function, k graphs at evenly spaced intervals between the min and max graph size of interest will be sampled. The difference at each point will be averaged along with the standard deviation used in a weighted sum to give each parse tree a fitness value.
The GP will be using standard GP operators along with other operators to help with a local search of the parse trees. The standard GP operators include sub-tree crossover and sub-tree mutation. The new operator is an alternate mutation operator which randomly selects a node of the parse tree and randomly changes the parameters of the operation contained in that node. 



\end{document}


